{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Documents\\\\Projects\\\\ECommerce Customer Churn Prediction\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Documents\\\\Projects\\\\ECommerce Customer Churn Prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"data/interim/kaggle/raw_kaggle_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>...</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "      <th>source</th>\n",
       "      <th>data_last_updated_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Single</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.93</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>2025-02-23 13:01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Single</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.90</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>2025-02-23 13:01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Single</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.28</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>2025-02-23 13:01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Single</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.07</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>2025-02-23 13:01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Single</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.60</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>2025-02-23 13:01:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
       "0       50001      1     4.0         Mobile Phone         3              6.0   \n",
       "1       50002      1     NaN                Phone         1              8.0   \n",
       "2       50003      1     NaN                Phone         1             30.0   \n",
       "3       50004      1     0.0                Phone         3             15.0   \n",
       "4       50005      1     0.0                Phone         1             12.0   \n",
       "\n",
       "  PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  ...  \\\n",
       "0           Debit Card  Female             3.0                         3  ...   \n",
       "1                  UPI    Male             3.0                         4  ...   \n",
       "2           Debit Card    Male             2.0                         4  ...   \n",
       "3           Debit Card    Male             2.0                         4  ...   \n",
       "4                   CC    Male             NaN                         3  ...   \n",
       "\n",
       "  MaritalStatus  NumberOfAddress Complain  OrderAmountHikeFromlastYear  \\\n",
       "0        Single                9        1                         11.0   \n",
       "1        Single                7        1                         15.0   \n",
       "2        Single                6        1                         14.0   \n",
       "3        Single                8        0                         23.0   \n",
       "4        Single                3        0                         11.0   \n",
       "\n",
       "   CouponUsed  OrderCount  DaySinceLastOrder  CashbackAmount  source  \\\n",
       "0         1.0         1.0                5.0          159.93  kaggle   \n",
       "1         0.0         1.0                0.0          120.90  kaggle   \n",
       "2         0.0         1.0                3.0          120.28  kaggle   \n",
       "3         0.0         1.0                3.0          134.07  kaggle   \n",
       "4         1.0         1.0                3.0          129.60  kaggle   \n",
       "\n",
       "   data_last_updated_dt  \n",
       "0   2025-02-23 13:01:41  \n",
       "1   2025-02-23 13:01:41  \n",
       "2   2025-02-23 13:01:41  \n",
       "3   2025-02-23 13:01:41  \n",
       "4   2025-02-23 13:01:41  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2815 entries, 0 to 2814\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   2815 non-null   int64  \n",
      " 1   Churn                        2815 non-null   int64  \n",
      " 2   Tenure                       2551 non-null   float64\n",
      " 3   PreferredLoginDevice         2815 non-null   object \n",
      " 4   CityTier                     2815 non-null   int64  \n",
      " 5   WarehouseToHome              2564 non-null   float64\n",
      " 6   PreferredPaymentMode         2815 non-null   object \n",
      " 7   Gender                       2815 non-null   object \n",
      " 8   HourSpendOnApp               2560 non-null   float64\n",
      " 9   NumberOfDeviceRegistered     2815 non-null   int64  \n",
      " 10  PreferedOrderCat             2815 non-null   object \n",
      " 11  SatisfactionScore            2815 non-null   int64  \n",
      " 12  MaritalStatus                2815 non-null   object \n",
      " 13  NumberOfAddress              2815 non-null   int64  \n",
      " 14  Complain                     2815 non-null   int64  \n",
      " 15  OrderAmountHikeFromlastYear  2744 non-null   float64\n",
      " 16  CouponUsed                   2653 non-null   float64\n",
      " 17  OrderCount                   2704 non-null   float64\n",
      " 18  DaySinceLastOrder            2740 non-null   float64\n",
      " 19  CashbackAmount               2815 non-null   float64\n",
      " 20  source                       2815 non-null   object \n",
      " 21  data_last_updated_dt         2815 non-null   object \n",
      "dtypes: float64(8), int64(7), object(7)\n",
      "memory usage: 484.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import CONFIG_PATH,PARAMS_PATH,SCHEMA_PATH\n",
    "from src.utils.common import read_yaml\n",
    "from src.entity.data_ingestion import DataIngestionConfig\n",
    "from src.entity.data_storage import DataStorageConnectionConfig\n",
    "from src.entity.data_validation import DataValidationConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_path=CONFIG_PATH,params_path=PARAMS_PATH,schema_path=SCHEMA_PATH):\n",
    "        self.config=read_yaml(config_path),\n",
    "        self.params=read_yaml(params_path),\n",
    "        self.schema=read_yaml(schema_path)\n",
    "    def get_data_ingestion_config(self)->DataIngestionConfig:\n",
    "        config=self.config[0].data\n",
    "        data_ingestion=DataIngestionConfig(\n",
    "            kaggle_dataset=config.kaggle_source_path,\n",
    "            gdrive_dataset=config.gdrive_source_path,\n",
    "            local_dataset=config.raw,\n",
    "            staging_dataset=config.interim\n",
    "        )\n",
    "        return data_ingestion\n",
    "    def get_data_storage_config(self)->DataStorageConnectionConfig:\n",
    "        config=self.config[0].sql\n",
    "        data_connection=DataStorageConnectionConfig(\n",
    "            server_name=config.server_name,\n",
    "            db_name=config.db_name,\n",
    "            driver_name=config.driver_name,\n",
    "            trusted_conn=config.trusted_conn,\n",
    "            kaggle_table=config.kaggle_table_name,\n",
    "            gdrive_table=config.gdrive_table_name\n",
    "        )\n",
    "        return data_connection\n",
    "    def get_data_validation_config(self)->DataValidationConfig:\n",
    "        config=self.config[0].data_validation\n",
    "        schema=self.schema.COLUMNS\n",
    "        data_validation=DataValidationConfig(\n",
    "            data_source_path_kaggle=config.data_source_kaggle,\n",
    "            data_source_path_gdrive=config.data_source_gdrive,\n",
    "            Status_report=config.STATUS_REPORT_FILE,\n",
    "            all_schema=schema\n",
    "        )\n",
    "        return data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-23 17:16:17,134 : INFO: common: yaml file config\\config.yaml loaded successfully!]\n",
      "[2025-02-23 17:16:17,145 : INFO: common: yaml file config\\params.yaml loaded successfully!]\n",
      "[2025-02-23 17:16:17,156 : INFO: common: yaml file config\\schema.yaml loaded successfully!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataValidationConfig(data_source_path_kaggle='data/interim/kaggle/', data_source_path_gdrive='data/interim/gdrive/', Status_report='docs/data_validation/status_report.txt', all_schema=ConfigBox({'CustomerID': 'int64', 'Tenure': 'float64', 'PreferredLoginDevice': 'object', 'CityTier': 'int64', 'WarehouseToHome': 'float64', 'PreferredPaymentMode': 'object', 'Gender': 'object', 'HourSpendOnApp': 'float64', 'NumberOfDeviceRegistered': 'int64', 'PreferedOrderCat': 'object', 'SatisfactionScore': 'int64', 'MaritalStatus': 'object', 'NumberOfAddress': 'int64', 'Complain': 'int64', 'OrderAmountHikeFromlastYear': 'float64', 'CouponUsed': 'float64', 'OrderCount': 'float64', 'DaySinceLastOrder': 'float64', 'CashbackAmount': 'float64'}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config=ConfigurationManager()\n",
    "config.get_data_validation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import shutil\n",
    "import gdown\n",
    "from src.configuration.config import ConfigurationManager\n",
    "from src.logger import logger\n",
    "from datetime import datetime\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self,config=DataValidationConfig):\n",
    "        self.data_config=config\n",
    "    def validate_all_columns(self)->bool:\n",
    "        try:\n",
    "            validation_status=None\n",
    "            data=pd.read_csv(self.config)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid=DataValidation()\n",
    "data_valid.validate_all_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-23 16:51:41,174 : INFO: file_data_context: FileDataContext loading fluent config]\n",
      "[2025-02-23 16:51:41,181 : INFO: config: Loading 'datasources' ->\n",
      "[]]\n",
      "[2025-02-23 16:51:41,389 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-23 16:51:41,393 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-23 16:51:41,425 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-23 16:51:41,429 : INFO: fluent_base_model: DataFrameAsset.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-23 16:51:41,431 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-23 16:51:41,460 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-23 16:51:41,464 : INFO: fluent_base_model: DataFrameAsset.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-23 16:51:41,467 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 10/10 [00:00<00:00, 204.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge \n",
    "df=pd.read_csv(\"data/interim/kaggle/raw_kaggle_churn_data.csv\")\n",
    "context=ge.get_context(mode='file')\n",
    "base_directory = \"reports/\"  # this is the default path (relative to the root folder of the Data Context) but can be changed as required\n",
    "site_config = {\n",
    "    \"class_name\": \"SiteBuilder\",\n",
    "    \"site_index_builder\": {\"class_name\": \"DefaultSiteIndexBuilder\"},\n",
    "    \"store_backend\": {\n",
    "        \"class_name\": \"TupleFilesystemStoreBackend\",\n",
    "        \"base_directory\": base_directory,\n",
    "    },\n",
    "}\n",
    "site_name = \"my_data_docs_site\"\n",
    "context.build_data_docs(site_names=site_name)\n",
    "context.add_data_docs_site(site_name=site_name, site_config=site_config)\n",
    "\n",
    "data_source=context.data_sources.add_pandas(\"pandas\")\n",
    "data_asset=data_source.add_dataframe_asset(name=\"pd dataframe asset\")\n",
    "batch_defintion=data_asset.add_batch_definition_whole_dataframe(\"batch_definition\")\n",
    "batch=batch_defintion.get_batch(batch_parameters={\"dataframe\":df})\n",
    "expectation=ge.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"CityTier\",max_value=3,min_value=1\n",
    ")\n",
    "validation=batch.validate(expectation,result_format='COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  30%|███       | 3/10 [00:00<00:00, 333.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 10/10 [00:00<00:00, 227.27it/s]\n"
     ]
    }
   ],
   "source": [
    "expectation=ge.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"CityTier\",max_value=3,min_value=1\n",
    ")\n",
    "validation=batch.validate(expectation,result_format='COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_json(validation)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.read_json(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"expectation_config\": {\n",
      "    \"type\": \"expect_column_values_to_be_between\",\n",
      "    \"kwargs\": {\n",
      "      \"batch_id\": \"pandas-pd dataframe asset\",\n",
      "      \"column\": \"CityTier\",\n",
      "      \"min_value\": 1.0,\n",
      "      \"max_value\": 3.0\n",
      "    },\n",
      "    \"meta\": {}\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 2815,\n",
      "    \"unexpected_count\": 0,\n",
      "    \"unexpected_percent\": 0.0,\n",
      "    \"partial_unexpected_list\": [],\n",
      "    \"missing_count\": 0,\n",
      "    \"missing_percent\": 0.0,\n",
      "    \"unexpected_percent_total\": 0.0,\n",
      "    \"unexpected_percent_nonmissing\": 0.0,\n",
      "    \"partial_unexpected_counts\": [],\n",
      "    \"partial_unexpected_index_list\": [],\n",
      "    \"unexpected_list\": [],\n",
      "    \"unexpected_index_list\": [],\n",
      "    \"unexpected_index_query\": \"df.filter(items=[], axis=0)\"\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoDataDocsError",
     "evalue": "No Data Docs found. Please check that you have run a checkpoint, and that the checkpoint has a UpdateDataDocsAction in its actions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoDataDocsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_data_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:1621\u001b[0m, in \u001b[0;36mAbstractDataContext.open_data_docs\u001b[1;34m(self, resource_identifier, site_name, only_if_exists)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_data_docs\u001b[39m(\n\u001b[0;32m   1604\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1605\u001b[0m     resource_identifier: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1606\u001b[0m     site_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1607\u001b[0m     only_if_exists: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1608\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;124;03m    A stdlib cross-platform way to open a file in a browser.\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;124;03m        only_if_exists: Optionally specify flag to pass to \"self.get_docs_sites_urls()\".\u001b[39;00m\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_data_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_identifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43msite_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msite_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_if_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_if_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:1642\u001b[0m, in \u001b[0;36mAbstractDataContext._open_data_docs\u001b[1;34m(self, resource_identifier, site_name, only_if_exists)\u001b[0m\n\u001b[0;32m   1639\u001b[0m urls_to_open \u001b[38;5;241m=\u001b[39m [url \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m nullable_urls \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m urls_to_open:\n\u001b[1;32m-> 1642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m gx\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mNoDataDocsError\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls_to_open:\n\u001b[0;32m   1645\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpening Data Docs found here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNoDataDocsError\u001b[0m: No Data Docs found. Please check that you have run a checkpoint, and that the checkpoint has a UpdateDataDocsAction in its actions."
     ]
    }
   ],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3222ab8ff82c475ab10683165ef56052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21b6a039a634bf6aaea7b8174fe1e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "context=ge.get_context()\n",
    "context.build_data_docs()\n",
    "\n",
    "validator=context.sources.pandas_default.read_csv(\"data/interim/kaggle/raw_kaggle_churn_data.csv\")\n",
    "\n",
    "validator.expect_column_values_to_be_between(column=\"CityTier\",max_value=3,min_value=1)\n",
    "\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "checkpoint=context.add_or_update_checkpoint(\n",
    "    name=\"checkpoint\",\n",
    "    validator=validator,\n",
    ")\n",
    "checkpoint_result=checkpoint.run()\n",
    "context.view_validation_result(checkpoint_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Documents\\\\Projects\\\\ECommerce Customer Churn Prediction\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\serializable_data_context.py:160: UserWarning:\n",
      "\n",
      "Warning. An existing `great_expectations.yml` was found here: c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx.\n",
      "    - No action was taken.\n",
      "\n",
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\serializable_data_context.py:168: UserWarning:\n",
      "\n",
      "Warning. An existing `config_variables.yml` was found here:\n",
      "            c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\uncommitted. - No action was taken.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'save_expectation_suite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m expectation\u001b[38;5;241m=\u001b[39mgx\u001b[38;5;241m.\u001b[39mexpectations\u001b[38;5;241m.\u001b[39mExpectColumnValuesToBeBetween(\n\u001b[0;32m     20\u001b[0m     column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCityTier\u001b[39m\u001b[38;5;124m\"\u001b[39m,max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#batch.add_(expectation)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_expectation_suite\u001b[49m()\n\u001b[0;32m     24\u001b[0m validation_result \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mvalidate(expectation)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(validation_result)  \u001b[38;5;66;03m# Print the validation result in JSON format\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'save_expectation_suite'"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"data/interim/kaggle/raw_kaggle_churn_data.csv\"\n",
    ")\n",
    "\n",
    "context = gx.get_context(context_root_dir=\"great_expectations\")\n",
    "data_source = context.data_sources.add_pandas(\"pandas\")\n",
    "data_asset = data_source.add_dataframe_asset(name=\"pd dataframe asset\")\n",
    "\n",
    "\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
    "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})\n",
    "\n",
    "expectation_suite_name=\"my expectation suite\"\n",
    "#context.add_or_update_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "expectation=gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"CityTier\",max_value=3,min_value=1\n",
    ")\n",
    "#batch.add_(expectation)\n",
    "batch.save_expectation_suite()\n",
    "validation_result = batch.validate(expectation)\n",
    "print(validation_result)  # Print the validation result in JSON format\n",
    "\n",
    "# Build and open data docs\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrender\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mview\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultMarkdownPageView\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrender\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RenderedDocumentContent\n\u001b[1;32m----> 5\u001b[0m rendered_content\u001b[38;5;241m=\u001b[39m\u001b[43mValidationResultsPageRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m html_report\u001b[38;5;241m=\u001b[39mDefaultMarkdownPageView()\u001b[38;5;241m.\u001b[39mrender(RenderedDocumentContent(rendered_content))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_validation.html\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\render\\renderer\\page_renderer.py:78\u001b[0m, in \u001b[0;36mValidationResultsPageRenderer.render\u001b[1;34m(self, validation_results, suite_parameters)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     validation_results: ExpectationSuiteValidationResult,\n\u001b[0;32m     75\u001b[0m     suite_parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m ):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Gather run identifiers\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     run_name, run_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_run_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     expectation_suite_name \u001b[38;5;241m=\u001b[39m validation_results\u001b[38;5;241m.\u001b[39msuite_name\n\u001b[0;32m     80\u001b[0m     batch_kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     81\u001b[0m         validation_results\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m validation_results\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m     84\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\render\\renderer\\page_renderer.py:136\u001b[0m, in \u001b[0;36mValidationResultsPageRenderer._parse_run_values\u001b[1;34m(self, validation_results)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_parse_run_values\u001b[39m(\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m, validation_results: ExpectationSuiteValidationResult\n\u001b[0;32m    135\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 136\u001b[0m     run_id: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, RunIdentifier] \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run_id, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'run_id'"
     ]
    }
   ],
   "source": [
    "from great_expectations.render.renderer import ValidationResultsPageRenderer\n",
    "from great_expectations.render.view import DefaultMarkdownPageView\n",
    "from great_expectations.render.components import RenderedDocumentContent\n",
    "\n",
    "rendered_content=ValidationResultsPageRenderer().render(validation_results=validation_result)\n",
    "html_report=DefaultMarkdownPageView().render(RenderedDocumentContent(rendered_content))\n",
    "\n",
    "with open(\"data_validation.html\",\"w\") as f:\n",
    "    f.write(html_report)\n",
    "print(\"Valdation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ValidationDefinition\nsuite\n  Suite must be a dictionary (if being deserialized) or an ExpectationSuite object. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m expectation\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m     43\u001b[0m definition_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_validation_definition\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 44\u001b[0m validation_definition\u001b[38;5;241m=\u001b[39m\u001b[43mgx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mValidationDefinition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_definition\u001b[49m\u001b[43m,\u001b[49m\u001b[43msuite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpectation_suite_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefinition_name\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m validation_definition \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mvalidation_definitions\u001b[38;5;241m.\u001b[39madd(validation_definition)\n\u001b[0;32m     48\u001b[0m validator \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mvalidate(expectation)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ValidationDefinition\nsuite\n  Suite must be a dictionary (if being deserialized) or an ExpectationSuite object. (type=value_error)"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "import pandas as pd\n",
    "from great_expectations import checkpoint\n",
    "\n",
    "# Load your CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(\"data/interim/kaggle/raw_kaggle_churn_data.csv\")\n",
    "\n",
    "# Initialize the DataContext\n",
    "context = gx.get_context()\n",
    "\n",
    "# Add a Pandas datasource\n",
    "datasource = context.data_sources.add_pandas(name=\"my_pandas_datasource\")\n",
    "\n",
    "# Create a data asset from the DataFrame\n",
    "data_asset = datasource.add_dataframe_asset(name=\"my_dataframe_asset\")\n",
    "\n",
    "# Build a batch request using RuntimeBatchRequest\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
    "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})\n",
    "# Create an expectation suite\n",
    "expectation_suite_name = \"my_expectation_suite\"\n",
    "suite=gx.ExpectationSuite(name=expectation_suite_name)\n",
    "suite=context.suites.add(suite)\n",
    "\n",
    "# Get a validator\n",
    "\n",
    "expectation=gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"WarehouseToHome\", min_value=5, max_value=126\n",
    ")\n",
    "# Add expectation for \"CityTier\" values between 1 and 3\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "        column=\"CityTier\", min_value=1, max_value=3\n",
    "    )\n",
    ")\n",
    "suite.add_expectation(expectation=expectation)\n",
    "\n",
    "\n",
    "# Save the expectation suite\n",
    "expectation.save()\n",
    "\n",
    "definition_name=\"my_validation_definition\"\n",
    "validation_definition=gx.ValidationDefinition(\n",
    "    data=batch_definition,suite=expectation_suite_name,name=definition_name\n",
    ")\n",
    "validation_definition = context.validation_definitions.add(validation_definition)\n",
    "validator = batch.validate(expectation)\n",
    "# Run validation\n",
    "checkpoint_result = checkpoint.run()\n",
    "print(checkpoint_result)  # Print results\n",
    "\n",
    "# Build and open data docs\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Received a \"pandas.DataFrame\" instance. It is recommended to pass a \"deepchecks.tabular.Dataset\" instance by initializing it with the data and metadata, for example by doing \"Dataset(dataframe, label=label, cat_features=cat_features)\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 18 categorical features were inferred.: Churn, PreferredLoginDevice, CityTier, PreferredPaymentMode, Gender, HourSpendOnApp, NumberOfDeviceRegistered... For full list use dataset.cat_features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\deepchecks\\tabular\\suite.py:117: DeprecationWarning:\n",
      "\n",
      "the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "\n",
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\deepchecks\\utils\\correlation_methods.py:102: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2596: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2596: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2596: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c4827741a448678bc090ad7e36f855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_906GRD7IH42XXJQM7NUD4I2I9\">Data Integrity Sui…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import data_integrity\n",
    "\n",
    "integ_suite=data_integrity()\n",
    "df = pd.read_csv(\n",
    "    \"data/interim/kaggle/raw_kaggle_churn_data.csv\"\n",
    ")\n",
    "suite_result=integ_suite.run(df)\n",
    "\n",
    "suite_result.save_as_(\"reports/validation_report.html\")\n",
    "suite_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataContextError",
     "evalue": "Datasource is not a FluentDatasource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataContextError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m\n\u001b[0;32m      7\u001b[0m context\u001b[38;5;241m=\u001b[39mge\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m      8\u001b[0m datasource_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_csv_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     },\n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_datasource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdatasource_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:709\u001b[0m, in \u001b[0;36mAbstractDataContext.add_datasource\u001b[1;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;129m@new_argument\u001b[39m(\n\u001b[0;32m    683\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    684\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.15.49\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    693\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FluentDatasource \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a new Datasource to the data context, with configuration provided as kwargs.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m    --Documentation--\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;124;03m        Datasource instance added.\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\venv\\Lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:749\u001b[0m, in \u001b[0;36mAbstractDataContext._add_datasource\u001b[1;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_fluent_datasource(\n\u001b[0;32m    746\u001b[0m         datasource\u001b[38;5;241m=\u001b[39mdatasource,\n\u001b[0;32m    747\u001b[0m     )\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataContextError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource is not a FluentDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: TRY003 # FIXME CoP\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasource\n",
      "\u001b[1;31mDataContextError\u001b[0m: Datasource is not a FluentDatasource"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge \n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "df = pd.read_csv(\n",
    "    \"data/interim/kaggle/raw_kaggle_churn_data.csv\"\n",
    ")\n",
    "\n",
    "context=ge.get_context()\n",
    "\n",
    "\n",
    "context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03a5adc8d14420c8cdf80ef5eb88d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations import expectations as gxe\n",
    "import pandas as pd\n",
    "from great_expectations.checkpoint import UpdateDataDocsAction\n",
    "\n",
    "#generating context\n",
    "context=gx.get_context(mode='file')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"data/interim/kaggle/raw_kaggle_churn_data.csv\"\n",
    ")\n",
    "\n",
    "#giving a data source name to identify all data sources uniquely\n",
    "datasource = context.data_sources.add_pandas(name=\"my_pandas_datasource\")\n",
    "\n",
    "# Create a data asset from the DataFrame\n",
    "data_asset = datasource.add_dataframe_asset(name=\"my_dataframe_asset\")\n",
    "\n",
    "# Build a batch request using RuntimeBatchRequest\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
    "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})\n",
    "\n",
    "#Organize expectation suite\n",
    "suite_name=\"my_expectation_suite\"\n",
    "suite=gx.ExpectationSuite(name=suite_name)\n",
    "suite=context.suites.add(suite)\n",
    "expectation=gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"WarehouseToHome\", min_value=5, max_value=126\n",
    ")\n",
    "suite.add_expectation(expectation)\n",
    "expectation.save()\n",
    "# validation definition name\n",
    "validation_definition_name=\"dataset\"\n",
    "validation_definition=gx.ValidationDefinition(\n",
    "    data=batch_definition, suite=suite,name=validation_definition_name\n",
    ")\n",
    "validation=context.validation_definitions.add(validation_definition)\n",
    "#validation_result=validation.run(batch_parameters={\"dataframe\":df})\n",
    "#print(validation_result)\n",
    "\n",
    "# Define actions\n",
    "action_list=[\n",
    "    UpdateDataDocsAction(\n",
    "        name=\"update_all_data_docs\"\n",
    "    )\n",
    "]\n",
    "#create checkpoint\n",
    "validation_defintions=[context.validation_definitions.get(\"dataset\")]\n",
    "checkpoint_name=\"first check\" \n",
    "checkpoint=gx.Checkpoint(\n",
    "    name=checkpoint_name,\n",
    "    validation_definitions=validation_defintions,\n",
    "    actions=action_list,\n",
    "    result_format={\"result_format\":\"COMPLETE\"}\n",
    ")\n",
    "\n",
    "#save the checkpoint\n",
    "context.checkpoints.add(checkpoint)\n",
    "\n",
    "validation_result=checkpoint.run(\n",
    "    batch_parameters={\"dataframe\":df}\n",
    ")\n",
    "\n",
    "\n",
    "#Configure Data Docs\n",
    "base_directory = \"uncommitted/data_docs/local_site/\"  # this is the default path (relative to the root folder of the Data Context) but can be changed as required\n",
    "site_config = {\n",
    "    \"class_name\": \"SiteBuilder\",\n",
    "    \"site_index_builder\": {\"class_name\": \"DefaultSiteIndexBuilder\"},\n",
    "    \"store_backend\": {\n",
    "        \"class_name\": \"TupleFilesystemStoreBackend\",\n",
    "        \"base_directory\": base_directory,\n",
    "    },\n",
    "}\n",
    "site_name=\"my_data_docs_site\"\n",
    "\n",
    "context.add_data_docs_site(site_name=site_name,site_config=site_config)\n",
    "\n",
    "context.build_data_docs(site_names=site_name)\n",
    "\n",
    "context.open_data_docs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asus\\\\Documents\\\\Projects\\\\ECommerce Customer Churn Prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations import expectations as gxe\n",
    "import pandas as pd\n",
    "from great_expectations.checkpoint import UpdateDataDocsAction\n",
    "from src.utils.common import read_yaml\n",
    "from src.constants import CONFIG_PATH,PARAMS_PATH,SCHEMA_PATH\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import CONFIG_PATH,PARAMS_PATH,SCHEMA_PATH\n",
    "from src.utils.common import read_yaml\n",
    "from src.entity.data_ingestion import DataIngestionConfig\n",
    "from src.entity.data_storage import DataStorageConnectionConfig\n",
    "from src.entity.data_validation import DataValidationConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_path=CONFIG_PATH,params_path=PARAMS_PATH,schema_path=SCHEMA_PATH):\n",
    "        self.config=read_yaml(config_path),\n",
    "        self.params=read_yaml(params_path),\n",
    "        self.schema=read_yaml(schema_path)\n",
    "    def get_data_ingestion_config(self)->DataIngestionConfig:\n",
    "        config=self.config[0].data\n",
    "        data_ingestion=DataIngestionConfig(\n",
    "            kaggle_dataset=config.kaggle_source_path,\n",
    "            gdrive_dataset=config.gdrive_source_path,\n",
    "            local_dataset=config.raw,\n",
    "            staging_dataset=config.interim\n",
    "        )\n",
    "        return data_ingestion\n",
    "    def get_data_storage_config(self)->DataStorageConnectionConfig:\n",
    "        config=self.config[0].sql\n",
    "        data_connection=DataStorageConnectionConfig(\n",
    "            server_name=config.server_name,\n",
    "            db_name=config.db_name,\n",
    "            driver_name=config.driver_name,\n",
    "            trusted_conn=config.trusted_conn,\n",
    "            kaggle_table=config.kaggle_table_name,\n",
    "            gdrive_table=config.gdrive_table_name\n",
    "        )\n",
    "        return data_connection\n",
    "    def get_data_validation_config(self)->DataValidationConfig:\n",
    "        config=self.config[0].data_validation,\n",
    "        schema=self.schema.COLUMNS\n",
    "        print(config)\n",
    "        data_validation=DataValidationConfig(\n",
    "            data_source_path_kaggle=config[0].data_source_kaggle,\n",
    "            data_source_path_gdrive=config[0].data_source_gdrive,\n",
    "            Status_report=config[0].STATUS_REPORT_FILE,\n",
    "            all_schema=schema\n",
    "        )\n",
    "        return data_validation\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "class DataValidation:\n",
    "    def __init__(self):\n",
    "        self.config=ConfigurationManager().get_data_validation_config()\n",
    "    def run_validation(self):\n",
    "        #Create a context\n",
    "        if(os.path.exists(\"gx/\") and os.path.isdir(\"gx/\")):\n",
    "            shutil.rmtree(\"gx/\")\n",
    "        context=gx.get_context(mode='file')\n",
    "        #read data into dataframe\n",
    "        df_kaggle = pd.read_csv(self.config.data_source_path_kaggle+\"raw_kaggle_churn_data.csv\")\n",
    "        df_gdrive = pd.read_csv(self.config.data_source_path_gdrive+\"raw_gdrive_churn_data.csv\")\n",
    "        combined_df=pd.concat([df_kaggle,df_gdrive],axis=0)\n",
    "        #giving a data source name to identify all data sources uniquely\n",
    "        datasource = context.data_sources.add_pandas(name=\"churn_data_source\")\n",
    "\n",
    "        # Create a data asset from the DataFrame\n",
    "        data_asset = datasource.add_dataframe_asset(name=\"churn_data_asset\")\n",
    "\n",
    "        # Build a batch request using whole dataframe\n",
    "        batch_definition = data_asset.add_batch_definition_whole_dataframe(\"bulk batch\")\n",
    "        batch = batch_definition.get_batch(batch_parameters={\"dataframe\": combined_df})\n",
    "        \n",
    "        #Organize expectation suite\n",
    "        col_existence_suite_name=\"Column existence validation suite\"\n",
    "        col_suite=gx.ExpectationSuite(name=col_existence_suite_name)\n",
    "        \n",
    "        is_datatype_same_suite=\"Data Type Check Suite\"\n",
    "        type_suite=gx.ExpectationSuite(name=is_datatype_same_suite)\n",
    "        suite_1=context.suites.add(col_suite)\n",
    "        suite_2=context.suites.add(type_suite)\n",
    "        # expectation=gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "        #     column=\"WarehouseToHome\", min_value=5, max_value=126\n",
    "        # )\n",
    "        schema=self.config.all_schema\n",
    "        for col in schema.keys():\n",
    "                expectation1=gx.expectations.ExpectColumnToExist(column=col)\n",
    "                suite_1.add_expectation(expectation1)\n",
    "        expectation1.save()\n",
    "        for col,dtype in schema.items():\n",
    "            try:\n",
    "                expectation2=gx.expectations.ExpectColumnValuesToBeOfType(column=col,type_=dtype)\n",
    "                suite_2.add_expectation(expectation2)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "                \n",
    "            \n",
    "        #suite.add_expectation(expectation)\n",
    "        expectation2.save()\n",
    "        # validation definition name\n",
    "        validation_definition_name_col=\"dataset_cols\"\n",
    "        validation_definition_cols=gx.ValidationDefinition(\n",
    "            data=batch_definition, suite=suite_1,name=validation_definition_name_col\n",
    "        )\n",
    "        validation_definition_name_type=\"dataset_types\"\n",
    "        validation_definition_types=gx.ValidationDefinition(\n",
    "            data=batch_definition, suite=suite_2,name=validation_definition_name_type\n",
    "        )\n",
    "        context.validation_definitions.add(validation_definition_cols)\n",
    "        context.validation_definitions.add(validation_definition_types)\n",
    "        action_list=[\n",
    "        UpdateDataDocsAction(\n",
    "        name=\"update_all_data_docs\"\n",
    "         )\n",
    "        ]\n",
    "        #create checkpoint\n",
    "        validation_defintions=[context.validation_definitions.get(\"dataset_types\"),\n",
    "        context.validation_definitions.get(\"dataset_cols\")]\n",
    "        checkpoint_name=\"first check\" \n",
    "        checkpoint=gx.Checkpoint(\n",
    "            name=checkpoint_name,\n",
    "            validation_definitions=validation_defintions,\n",
    "            actions=action_list,\n",
    "            result_format={\"result_format\":\"COMPLETE\"}\n",
    "        )\n",
    "\n",
    "        #save the checkpoint\n",
    "        context.checkpoints.add(checkpoint)\n",
    "\n",
    "        validation_result=checkpoint.run(\n",
    "            batch_parameters={\"dataframe\":combined_df}\n",
    "        )\n",
    "\n",
    "\n",
    "        #Configure Data Docs\n",
    "        base_directory = \"uncommitted/data_docs/local_site/\"  # this is the default path (relative to the root folder of the Data Context) but can be changed as required\n",
    "        site_config = {\n",
    "            \"class_name\": \"SiteBuilder\",\n",
    "            \"site_index_builder\": {\"class_name\": \"DefaultSiteIndexBuilder\"},\n",
    "            \"store_backend\": {\n",
    "                \"class_name\": \"TupleFilesystemStoreBackend\",\n",
    "                \"base_directory\": base_directory,\n",
    "            },\n",
    "        }\n",
    "        site_name=\"my_data_docs_site\"\n",
    "\n",
    "        context.add_data_docs_site(site_name=site_name,site_config=site_config)\n",
    "\n",
    "        context.build_data_docs(site_names=site_name)\n",
    "\n",
    "        return True\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-24 00:46:39,478 : INFO: common: yaml file config\\config.yaml loaded successfully!]\n",
      "[2025-02-24 00:46:39,485 : INFO: common: yaml file config\\params.yaml loaded successfully!]\n",
      "[2025-02-24 00:46:39,497 : INFO: common: yaml file config\\schema.yaml loaded successfully!]\n",
      "(ConfigBox({'data_source_kaggle': 'data/interim/kaggle/', 'data_source_gdrive': 'data/interim/gdrive/', 'STATUS_REPORT_FILE': 'uncommitted/data_docs/local_site/'}),)\n",
      "[2025-02-24 00:46:39,589 : INFO: file_data_context: FileDataContext loading fluent config]\n",
      "[2025-02-24 00:46:39,600 : INFO: config: Loading 'datasources' ->\n",
      "[]]\n",
      "[2025-02-24 00:46:39,767 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-24 00:46:39,770 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-24 00:46:39,815 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-24 00:46:39,819 : INFO: fluent_base_model: DataFrameAsset.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-24 00:46:39,823 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-24 00:46:39,862 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-24 00:46:39,865 : INFO: fluent_base_model: DataFrameAsset.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-24 00:46:39,868 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d194701b2084db5a9431039ac725597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-24 00:46:44,027 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,031 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,037 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,043 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,051 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,058 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,063 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,069 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,076 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,081 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,087 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,093 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,105 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,114 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,123 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,128 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,137 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,144 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,149 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,159 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,169 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,188 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,196 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,212 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,222 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,230 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,238 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,244 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,250 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,256 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,269 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,277 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,287 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,292 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,298 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,304 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,311 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,316 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,321 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,332 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,339 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,348 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,366 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,373 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd866e3c0ba348bda9f8b1bfbb1dfa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-24 00:46:44,433 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,439 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,442 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,445 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,450 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,457 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,463 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,471 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,478 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,483 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,488 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,491 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,496 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,499 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,502 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,506 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,509 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,512 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,516 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,523 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,528 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,536 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,540 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,546 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,552 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,558 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,565 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,568 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,574 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,578 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,582 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,586 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,590 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,597 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,603 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,610 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,618 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,626 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,633 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,637 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,641 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,647 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,651 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,658 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,666 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,671 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,677 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,684 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,692 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,754 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,781 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,794 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,805 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,812 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,818 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,822 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,827 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,830 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,834 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,840 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,849 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,852 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,861 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,868 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,879 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,884 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,905 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,911 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,914 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,916 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,920 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,923 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,926 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,929 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,931 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,931 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,931 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,931 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,944 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,947 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,952 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,955 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,958 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,959 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,959 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,967 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,970 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:44,973 : INFO: expectation: _get_default_value called with key \"table\", but it is not a known field]\n",
      "[2025-02-24 00:46:48,365 : INFO: file_data_context: Saving 1 Fluent Datasources to c:\\Users\\asus\\Documents\\Projects\\ECommerce Customer Churn Prediction\\gx\\great_expectations.yml]\n",
      "[2025-02-24 00:46:48,370 : INFO: fluent_base_model: DataFrameAsset.dict() - missing `config_provider`, skipping config substitution]\n",
      "[2025-02-24 00:46:48,374 : INFO: fluent_base_model: PandasDatasource.dict() - missing `config_provider`, skipping config substitution]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-24 00:47:16,464 : INFO: _common: Backing off send_request(...) for 0.2s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15))]\n",
      "[2025-02-24 00:47:46,425 : INFO: _common: Backing off send_request(...) for 0.9s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15))]\n",
      "[2025-02-24 00:48:17,533 : INFO: _common: Backing off send_request(...) for 2.3s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15))]\n"
     ]
    }
   ],
   "source": [
    "test=DataValidation()\n",
    "test.run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5630 entries, 0 to 2814\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   5630 non-null   int64  \n",
      " 1   Churn                        5630 non-null   int64  \n",
      " 2   Tenure                       5366 non-null   float64\n",
      " 3   PreferredLoginDevice         5630 non-null   object \n",
      " 4   CityTier                     5630 non-null   int64  \n",
      " 5   WarehouseToHome              5379 non-null   float64\n",
      " 6   PreferredPaymentMode         5630 non-null   object \n",
      " 7   Gender                       5630 non-null   object \n",
      " 8   HourSpendOnApp               5375 non-null   float64\n",
      " 9   NumberOfDeviceRegistered     5630 non-null   int64  \n",
      " 10  PreferedOrderCat             5630 non-null   object \n",
      " 11  SatisfactionScore            5630 non-null   int64  \n",
      " 12  MaritalStatus                5630 non-null   object \n",
      " 13  NumberOfAddress              5630 non-null   int64  \n",
      " 14  Complain                     5630 non-null   int64  \n",
      " 15  OrderAmountHikeFromlastYear  5365 non-null   float64\n",
      " 16  CouponUsed                   5374 non-null   float64\n",
      " 17  OrderCount                   5372 non-null   float64\n",
      " 18  DaySinceLastOrder            5323 non-null   float64\n",
      " 19  CashbackAmount               5630 non-null   float64\n",
      " 20  source                       5630 non-null   object \n",
      " 21  data_last_updated_dt         5630 non-null   object \n",
      "dtypes: float64(8), int64(7), object(7)\n",
      "memory usage: 1011.6+ KB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-23 23:18:00,508 : INFO: _common: Backing off send_request(...) for 2.7s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15))]\n",
      "[2025-02-23 23:18:34,806 : ERROR: _common: Giving up send_request(...) after 4 tries (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15))]\n",
      "[2025-02-23 23:18:34,808 : ERROR: consumer: error uploading: HTTPSConnectionPool(host='posthog.greatexpectations.io', port=443): Read timed out. (read timeout=15)]\n"
     ]
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv(\"data/interim/kaggle/raw_kaggle_churn_data.csv\")\n",
    "df_gdrive = pd.read_csv(\"data/interim/gdrive/raw_gdrive_churn_data.csv\")\n",
    "combined_df=pd.concat([df_kaggle,df_gdrive],axis=0)\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
